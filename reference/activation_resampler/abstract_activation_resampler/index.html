<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../img/favicon.ico" />
    <title>abstract_activation_resampler - Sparse Autoencoder</title>
    <link rel="stylesheet" href="../../../css/theme.css" />
    <link rel="stylesheet" href="../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../../../assets/_mkdocstrings.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "abstract_activation_resampler";
        var mkdocs_page_input_path = "reference/activation_resampler/abstract_activation_resampler.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../.." class="icon icon-home"> Sparse Autoencoder
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../getting_started/">Getting Started</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../contributing/">Contributing</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../../citation/">Citation</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Reference</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../../">Home</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">activation_resampler</a>
    <ul class="current">
                <li class="toctree-l2"><a class="reference internal" href="../">Index</a>
                </li>
                <li class="toctree-l2 current"><a class="reference internal current" href="./">abstract_activation_resampler</a>
    <ul class="current">
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">activation_store</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../activation_store/">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../activation_store/base_store/">base_store</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../activation_store/disk_store/">disk_store</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../activation_store/list_store/">list_store</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../activation_store/tensor_store/">tensor_store</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">utils</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../activation_store/utils/">Index</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../activation_store/utils/extend_resize/">extend_resize</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">autoencoder</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../autoencoder/">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../autoencoder/abstract_autoencoder/">abstract_autoencoder</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">components</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../autoencoder/components/">Index</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../autoencoder/components/abstract_decoder/">abstract_decoder</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../autoencoder/components/abstract_encoder/">abstract_encoder</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../autoencoder/components/abstract_outer_bias/">abstract_outer_bias</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../autoencoder/components/linear_encoder/">linear_encoder</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../autoencoder/components/tied_bias/">tied_bias</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../autoencoder/components/unit_norm_decoder/">unit_norm_decoder</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../autoencoder/model/">model</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">loss</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../loss/">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../loss/abstract_loss/">abstract_loss</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../loss/learned_activations_l1/">learned_activations_l1</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../loss/mse_reconstruction_loss/">mse_reconstruction_loss</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../loss/reducer/">reducer</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">metrics</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../metrics/">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../metrics/abstract_metric/">abstract_metric</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">optimizer</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../optimizer/">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../optimizer/abstract_optimizer/">abstract_optimizer</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../optimizer/adam_with_reset/">adam_with_reset</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">source_data</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../source_data/">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../source_data/abstract_dataset/">abstract_dataset</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../source_data/pretokenized_dataset/">pretokenized_dataset</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../source_data/random_int/">random_int</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../source_data/text_dataset/">text_dataset</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">src_model</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../src_model/">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../src_model/store_activations_hook/">store_activations_hook</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tensor_types/">tensor_types</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">train</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../train/">Index</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../train/abstract_pipeline/">abstract_pipeline</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../train/generate_activations/">generate_activations</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">metrics</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../train/metrics/">Index</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../train/metrics/capacity/">capacity</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../train/metrics/feature_density/">feature_density</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../train/pipeline/">pipeline</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../train/resample_neurons/">resample_neurons</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../train/sweep_config/">sweep_config</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../train/train_autoencoder/">train_autoencoder</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">utils</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../train/utils/">Index</a>
                </li>
                <li class="toctree-l3"><a class="reference internal" href="../../train/utils/wandb_sweep_types/">wandb_sweep_types</a>
                </li>
    </ul>
                </li>
    </ul>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../..">Sparse Autoencoder</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">Reference</li>
          <li class="breadcrumb-item">activation_resampler</li>
      <li class="breadcrumb-item active">abstract_activation_resampler</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <div class="doc doc-object doc-module">



<a id="sparse_autoencoder.activation_resampler.abstract_activation_resampler"></a>
  <div class="doc doc-contents first">
  
      <p>Abstract activation resampler.</p>

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">




<h2 id="sparse_autoencoder.activation_resampler.abstract_activation_resampler.AbstractActivationResampler" class="doc doc-heading">
          <code>AbstractActivationResampler</code>


</h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="abc.ABC">ABC</span></code></p>

  
      <p>Abstract activation resampler.</p>

            <details class="quote">
              <summary>Source code in <code>sparse_autoencoder/activation_resampler/abstract_activation_resampler.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">AbstractActivationResampler</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Abstract activation resampler.&quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">resample_dead_neurons</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">neuron_activity</span><span class="p">:</span> <span class="n">NeuronActivity</span><span class="p">,</span>
        <span class="n">store</span><span class="p">:</span> <span class="n">TensorActivationStore</span><span class="p">,</span>
        <span class="n">num_input_activations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">819_200</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span>
        <span class="n">DeadEncoderNeuronWeightUpdates</span><span class="p">,</span> <span class="n">DeadEncoderNeuronBiasUpdates</span><span class="p">,</span> <span class="n">DeadDecoderNeuronWeightUpdates</span>
    <span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Resample dead neurons.</span>

<span class="sd">        Over the course of training, a subset of autoencoder neurons will have zero activity across</span>
<span class="sd">        a large number of datapoints. The authors of *Towards Monosemanticity: Decomposing Language</span>
<span class="sd">        Models With Dictionary Learning* found that “resampling” these dead neurons during training</span>
<span class="sd">        improves the number of likely-interpretable features (i.e., those in the high density</span>
<span class="sd">        cluster) and reduces total loss. This resampling may be compatible with the Lottery Ticket</span>
<span class="sd">        Hypothesis and increase the number of chances the network has to find promising feature</span>
<span class="sd">        directions.</span>

<span class="sd">        Warning:</span>
<span class="sd">            The optimizer should be reset after applying this function, as the Adam state will be</span>
<span class="sd">            incorrect for the modified weights and biases.</span>

<span class="sd">        Args:</span>
<span class="sd">            neuron_activity: Number of times each neuron fired. store: Activation store.</span>
<span class="sd">            store: TODO change.</span>
<span class="sd">            num_input_activations: Number of input activations to use when resampling. Will be</span>
<span class="sd">                rounded down to be divisible by the batch size, and cannot be larger than the number</span>
<span class="sd">                of items currently in the store.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">




<h3 id="sparse_autoencoder.activation_resampler.abstract_activation_resampler.AbstractActivationResampler.resample_dead_neurons" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">resample_dead_neurons</span><span class="p">(</span><span class="n">neuron_activity</span><span class="p">,</span> <span class="n">store</span><span class="p">,</span> <span class="n">num_input_activations</span><span class="o">=</span><span class="mi">819200</span><span class="p">)</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

</h3>


  <div class="doc doc-contents ">
  
      <p>Resample dead neurons.</p>
<p>Over the course of training, a subset of autoencoder neurons will have zero activity across
a large number of datapoints. The authors of <em>Towards Monosemanticity: Decomposing Language
Models With Dictionary Learning</em> found that “resampling” these dead neurons during training
improves the number of likely-interpretable features (i.e., those in the high density
cluster) and reduces total loss. This resampling may be compatible with the Lottery Ticket
Hypothesis and increase the number of chances the network has to find promising feature
directions.</p>

<details class="warning" open>
  <summary>Warning</summary>
  <p>The optimizer should be reset after applying this function, as the Adam state will be
incorrect for the modified weights and biases.</p>
</details>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>neuron_activity</code></b>
                  (<code><a class="autorefs autorefs-internal" title="sparse_autoencoder.tensor_types.NeuronActivity" href="../../tensor_types/#sparse_autoencoder.tensor_types.NeuronActivity">NeuronActivity</a></code>)
              –
              <div class="doc-md-description">
                <p>Number of times each neuron fired. store: Activation store.</p>
              </div>
            </li>
            <li>
              <b><code>store</code></b>
                  (<code><a class="autorefs autorefs-internal" title="sparse_autoencoder.activation_store.tensor_store.TensorActivationStore" href="../../activation_store/tensor_store/#sparse_autoencoder.activation_store.tensor_store.TensorActivationStore">TensorActivationStore</a></code>)
              –
              <div class="doc-md-description">
                <p>TODO change.</p>
              </div>
            </li>
            <li>
              <b><code>num_input_activations</code></b>
                  (<code>int</code>, default:
                      <code>819200</code>
)
              –
              <div class="doc-md-description">
                <p>Number of input activations to use when resampling. Will be
rounded down to be divisible by the batch size, and cannot be larger than the number
of items currently in the store.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
          <details class="quote">
            <summary> <code>sparse_autoencoder/activation_resampler/abstract_activation_resampler.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abstractmethod</span>
<span class="k">def</span> <span class="nf">resample_dead_neurons</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">neuron_activity</span><span class="p">:</span> <span class="n">NeuronActivity</span><span class="p">,</span>
    <span class="n">store</span><span class="p">:</span> <span class="n">TensorActivationStore</span><span class="p">,</span>
    <span class="n">num_input_activations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">819_200</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span>
    <span class="n">DeadEncoderNeuronWeightUpdates</span><span class="p">,</span> <span class="n">DeadEncoderNeuronBiasUpdates</span><span class="p">,</span> <span class="n">DeadDecoderNeuronWeightUpdates</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Resample dead neurons.</span>

<span class="sd">    Over the course of training, a subset of autoencoder neurons will have zero activity across</span>
<span class="sd">    a large number of datapoints. The authors of *Towards Monosemanticity: Decomposing Language</span>
<span class="sd">    Models With Dictionary Learning* found that “resampling” these dead neurons during training</span>
<span class="sd">    improves the number of likely-interpretable features (i.e., those in the high density</span>
<span class="sd">    cluster) and reduces total loss. This resampling may be compatible with the Lottery Ticket</span>
<span class="sd">    Hypothesis and increase the number of chances the network has to find promising feature</span>
<span class="sd">    directions.</span>

<span class="sd">    Warning:</span>
<span class="sd">        The optimizer should be reset after applying this function, as the Adam state will be</span>
<span class="sd">        incorrect for the modified weights and biases.</span>

<span class="sd">    Args:</span>
<span class="sd">        neuron_activity: Number of times each neuron fired. store: Activation store.</span>
<span class="sd">        store: TODO change.</span>
<span class="sd">        num_input_activations: Number of input activations to use when resampling. Will be</span>
<span class="sd">            rounded down to be divisible by the batch size, and cannot be larger than the number</span>
<span class="sd">            of items currently in the store.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../" class="btn btn-neutral float-left" title="Index"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../../activation_store/" class="btn btn-neutral float-right" title="Index">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../../activation_store/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../..";</script>
    <script src="../../../js/theme_extra.js"></script>
    <script src="../../../js/theme.js"></script>
      <script src="../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
