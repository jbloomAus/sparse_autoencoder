{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAE Quality of Life Improvements\n",
    "\n",
    "Add config to wandb run. \n",
    "Start saving the SAE weights mid-run. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparse_autoencoder import TensorActivationStore, SparseAutoencoder, pipeline\n",
    "from sparse_autoencoder.source_data.pile_uncopyrighted import PileUncopyrightedDataset\n",
    "from sparse_autoencoder.train.sweep_config import SweepParametersRuntime\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.utils import get_device, test_prompt\n",
    "from transformers import PreTrainedTokenizerBase\n",
    "import torch\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-instruct-1M into HookedTransformer\n",
      "Tokenized prompt: ['<|endoftext|>', '\\n', 'Once', ' upon', ' a', ' time', ',', ' there', ' lived', ' a', ' black', ' cat', '.', ' The', ' cat', ' belonged', ' to', ' a', ' little', ' girl', ' called', ' Katie', '.', ' Every', ' day', ',', ' Katie', '\\n', 'would', ' take', ' her', ' cat', ' for', ' a', ' walk', ' in', ' the', ' park', '.', '\\n', 'One', ' day', ',', ' as', ' Katie', ' and', ' her', ' cat', ' were', ' walking', ' around', ',', ' they', ' saw', ' a', ' mean', ' looking', ' man', '.', ' He', ' said', ' he', ' wanted', ' to', '\\n', 'take', ' the', ' cat', ',', ' to', ' which', ' she', ' replied', ' �', '�', 'This', ' cat', ' belongs', ' to', '\\n']\n",
      "Tokenized answer: [' me']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3519</span><span style=\"font-weight: bold\">     Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.03</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | me|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m3519\u001b[0m\u001b[1m     Logit:  \u001b[0m\u001b[1;36m4.03\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | me|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 20.20 Prob: 72.30% Token: |\n",
      "|\n",
      "Top 1th token. Logit: 18.09 Prob:  8.78% Token: |Kat|\n",
      "Top 2th token. Logit: 17.37 Prob:  4.28% Token: |Summary|\n",
      "Top 3th token. Logit: 17.29 Prob:  3.94% Token: |<|endoftext|>|\n",
      "Top 4th token. Logit: 16.76 Prob:  2.33% Token: |The|\n",
      "Top 5th token. Logit: 15.99 Prob:  1.08% Token: |John|\n",
      "Top 6th token. Logit: 15.49 Prob:  0.65% Token: |\"|\n",
      "Top 7th token. Logit: 15.31 Prob:  0.55% Token: |She|\n",
      "Top 8th token. Logit: 14.87 Prob:  0.35% Token: |Story|\n",
      "Top 9th token. Logit: 14.57 Prob:  0.26% Token: |G|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' me'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3519</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' me'\u001b[0m, \u001b[1;36m3519\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_model = HookedTransformer.from_pretrained(\n",
    "    \"tiny-stories-instruct-1M\", dtype=\"float32\"\n",
    ")\n",
    "\n",
    "# test the model\n",
    "example_prompt = \"\"\"\n",
    "Once upon a time, there lived a black cat. The cat belonged to a little girl called Katie. Every day, Katie\n",
    "would take her cat for a walk in the park.\n",
    "One day, as Katie and her cat were walking around, they saw a mean looking man. He said he wanted to\n",
    "take the cat, to which she replied ”This cat belongs to\n",
    "\"\"\"\n",
    "example_answer = \" me\"\n",
    "\n",
    "\n",
    "test_prompt(example_prompt, example_answer, src_model, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To train on Tiny Stories, we're going to need the tiny stories dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, final\n",
    "from sparse_autoencoder.source_data.abstract_dataset import (\n",
    "    SourceDataset,\n",
    "    TokenizedPrompts,\n",
    ")\n",
    "\n",
    "\n",
    "class TinyStoriesSourceDataBatch(TypedDict):\n",
    "    \"\"\"Pile Uncopyrighted Source Data.\n",
    "\n",
    "    https://huggingface.co/datasets/roneneldan/TinyStories\n",
    "    \"\"\"\n",
    "\n",
    "    text: list[str]\n",
    "    meta: list[dict[str, dict[str, str]]]\n",
    "\n",
    "\n",
    "@final\n",
    "class TinyStoriesDataset(SourceDataset[TinyStoriesSourceDataBatch]):\n",
    "    \"\"\"Tiny Stories Dataset.\n",
    "\n",
    "    https://huggingface.co/datasets/roneneldan/TinyStories\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "\n",
    "    def preprocess(\n",
    "        self,\n",
    "        source_batch: TinyStoriesSourceDataBatch,\n",
    "        *,\n",
    "        context_size: int,\n",
    "    ) -> TokenizedPrompts:\n",
    "        \"\"\"Preprocess a batch of prompts.\n",
    "\n",
    "        For each prompt's `text`, tokenize it and chunk into a list of tokenized prompts of length\n",
    "        `context_size`. For the last item in the chunk, throw it away if the length is less than\n",
    "        `context_size` (i.e. if it would otherwise require padding). Then finally flatten all\n",
    "        batches to a single list of tokenized prompts.\n",
    "\n",
    "        Args:\n",
    "            source_batch: A batch of source data. For example, with The Pile dataset this would be a\n",
    "                dict including the key \"text\" with a value of a list of strings (not yet tokenized).\n",
    "            context_size: The context size to use when returning a list of tokenized prompts.\n",
    "        \"\"\"\n",
    "        prompts: list[str] = source_batch[\"text\"]\n",
    "\n",
    "        tokenized_prompts = self.tokenizer(prompts)\n",
    "\n",
    "        # Chunk each tokenized prompt into blocks of context_size, discarding the last block if too\n",
    "        # small.\n",
    "        context_size_prompts = []\n",
    "        for encoding in list(tokenized_prompts[\"input_ids\"]):  # type: ignore\n",
    "            chunks = [\n",
    "                encoding[i : i + context_size]\n",
    "                for i in range(0, len(encoding), context_size)\n",
    "                if len(encoding[i : i + context_size]) == context_size\n",
    "            ]\n",
    "            context_size_prompts.extend(chunks)\n",
    "\n",
    "        return {\"input_ids\": context_size_prompts}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer: PreTrainedTokenizerBase,\n",
    "        context_size: int = 250,\n",
    "        buffer_size: int = 1000,\n",
    "        preprocess_batch_size: int = 1000,\n",
    "        dataset_path: str = \"roneneldan/TinyStories\",\n",
    "        dataset_split: str = \"train\",\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        super().__init__(\n",
    "            dataset_path=dataset_path,\n",
    "            dataset_split=dataset_split,\n",
    "            context_size=context_size,\n",
    "            buffer_size=buffer_size,\n",
    "            preprocess_batch_size=preprocess_batch_size,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an AutoEncoder for Tiny Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-instruct-1M into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjbloom\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path .cache/wandb/wandb/ wasn't writable, using system temp directory.\n",
      "wandb: WARNING Path .cache/wandb/wandb/ wasn't writable, using system temp directory\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c2856e5957400fa40dba46b067e276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112330934136279, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/wandb/run-20231109_152539-smpd2zcs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jbloom/sparse-autoencoder/runs/smpd2zcs' target=\"_blank\">eternal-valley-22</a></strong> to <a href='https://wandb.ai/jbloom/sparse-autoencoder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jbloom/sparse-autoencoder' target=\"_blank\">https://wandb.ai/jbloom/sparse-autoencoder</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jbloom/sparse-autoencoder/runs/smpd2zcs' target=\"_blank\">https://wandb.ai/jbloom/sparse-autoencoder/runs/smpd2zcs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7767aed9421644738e7d319173d82d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total activations trained on:   0%|          | 0/6000000 [00:00<?, ?it/s, Generate/train iterations=0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6d432336d2475cb5600f7094866fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/2000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db654a857a8540839943065afbf33ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/2000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65851806964b461194d0970fbcf6e867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/2000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713c065ffcad46d5b5ffe8827d2ac913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/2000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc04def458b45ba8245009d405014fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/2000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2f64b1c25c4c099e601cc68fa92854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/2000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1138e34a563b43429c8ae601b5e66bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.895 MB of 0.895 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>l1_loss</td><td>█▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▅▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>reconstruction_loss</td><td>█▆▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>l1_loss</td><td>1.22636</td></tr><tr><td>loss</td><td>0.00205</td></tr><tr><td>reconstruction_loss</td><td>0.00082</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eternal-valley-22</strong> at: <a href='https://wandb.ai/jbloom/sparse-autoencoder/runs/smpd2zcs' target=\"_blank\">https://wandb.ai/jbloom/sparse-autoencoder/runs/smpd2zcs</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 5 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/tmp/wandb/run-20231109_152539-smpd2zcs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "\n",
    "src_model = HookedTransformer.from_pretrained(\n",
    "    \"tiny-stories-instruct-1M\", dtype=\"float32\"\n",
    ")\n",
    "src_d_model: int = src_model.cfg.d_model  # type: ignore\n",
    "\n",
    "tokenizer: PreTrainedTokenizerBase = src_model.tokenizer  # type: ignore\n",
    "max_items = 2_000_000\n",
    "store = TensorActivationStore(max_items, src_d_model, device)\n",
    "\n",
    "# Make Autoencoder\n",
    "src_model_activation_hook_point = \"blocks.0.hook_resid_pre\"\n",
    "autoencoder = SparseAutoencoder(src_d_model, src_d_model * 8, torch.zeros(src_d_model))\n",
    "autoencoder.to(device)\n",
    "\n",
    "# Make Source Data\n",
    "tokenizer: PreTrainedTokenizerBase = src_model.tokenizer  # type: ignore\n",
    "source_data = TinyStoriesDataset(tokenizer=tokenizer)\n",
    "\n",
    "# hyper parameter\n",
    "max_activations = 3 * max_items\n",
    "\n",
    "\n",
    "sweep_config = SweepParametersRuntime(\n",
    "    lr=1e-3,\n",
    "    batch_size=2048,\n",
    "    l1_coefficient=1e-3,\n",
    ")\n",
    "\n",
    "wandb.init(\n",
    "    project=\"sparse-autoencoder\", dir=\".cache/wandb\", config=sweep_config.__dict__\n",
    ")\n",
    "\n",
    "pipeline(\n",
    "    src_model=src_model,\n",
    "    src_model_activation_hook_point=src_model_activation_hook_point,\n",
    "    src_model_activation_layer=0,  # why do we need to specify this as well?\n",
    "    source_dataset=source_data,\n",
    "    activation_store=store,\n",
    "    num_activations_before_training=max_items,\n",
    "    sweep_parameters=sweep_config,\n",
    "    log_artifacts=True,\n",
    "    autoencoder=autoencoder,\n",
    "    device=device,\n",
    "    max_activations=max_activations,\n",
    ")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseAutoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (TiedBias): TiedBias(position=pre_encoder)\n",
       "    (Linear): Linear(in_features=64, out_features=512, bias=False)\n",
       "    (ReLU): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (ConstrainedUnitNormLinear): ConstrainedUnitNormLinear(in_features=512, out_features=64, bias=False)\n",
       "    (TiedBias): TiedBias(position=post_decoder)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.encoder.Linear.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_weights = autoencoder.encoder.Linear.weight.T.detach().cpu()\n",
    "print(encoder_weights.shape)\n",
    "centred_weights = encoder_weights - encoder_weights.mean(dim=0)\n",
    "px.bar(encoder_weights.norm(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a cosine similarity matrix\n",
    "import torch.nn.functional as F\n",
    "from scipy.cluster import hierarchy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_cosine_sim_heatmap(centred_weights):\n",
    "    data_array = F.cosine_similarity(\n",
    "        centred_weights.T.unsqueeze(1), centred_weights.T.unsqueeze(0), dim=2\n",
    "    )\n",
    "    df = pd.DataFrame(data_array.numpy())\n",
    "\n",
    "    linkage = hierarchy.linkage(data_array)\n",
    "    dendrogram = hierarchy.dendrogram(linkage, no_plot=True, color_threshold=-np.inf)\n",
    "    reordered_ind = dendrogram[\"leaves\"]\n",
    "    # reorder df by ind\n",
    "    df = df.iloc[reordered_ind, reordered_ind]\n",
    "    data_array = df.to_numpy()\n",
    "    fig = px.imshow(\n",
    "        data_array, color_continuous_scale=\"RdBu\", color_continuous_midpoint=0\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = get_cosine_sim_heatmap(centred_weights)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_weights = autoencoder.decoder[0].weight.detach().cpu()\n",
    "decoder_weights.shape\n",
    "\n",
    "centred_weights = decoder_weights - decoder_weights.mean(dim=0)\n",
    "px.bar(decoder_weights.norm(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = get_cosine_sim_heatmap(centred_weights)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at token intersection with encoder weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_alignment = src_model.W_E.cpu() @ encoder_weights.cpu()\n",
    "token_alignment = token_alignment.T.detach()\n",
    "token_alignment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(token_alignment.norm(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"token\": token_strings,\n",
    "        \"projection\": token_alignment[442],\n",
    "    }\n",
    ")\n",
    "df.sort_values(\"projection\", ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_strings = tokenizer.convert_ids_to_tokens(list(tokenizer.vocab.values()))\n",
    "# sort the strings by the keys in tokenizer vocab\n",
    "token_strings = [x for _, x in sorted(zip(tokenizer.vocab.keys(), token_strings))]\n",
    "token_strings[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
