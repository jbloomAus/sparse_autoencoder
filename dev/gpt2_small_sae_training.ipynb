{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training SAE's for Copy Suppression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170c9a1bee25409981a36b60f5ebd430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 135.0 million tokens\n"
     ]
    }
   ],
   "source": [
    "# Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import wandb\n",
    "\n",
    "\n",
    "from sparse_autoencoder import TensorActivationStore, SparseAutoencoder, pipeline\n",
    "from sparse_autoencoder.source_data.pile_uncopyrighted import PileUncopyrightedDataset\n",
    "from sparse_autoencoder.train.sweep_config import SweepParametersRuntime\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.utils import get_device\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "import torch\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "# We want to work with GPT2 since it's small and has the copy suppression results.\n",
    "model_name = \"gpt2\"\n",
    "precision = \"float32\"\n",
    "src_model = HookedTransformer.from_pretrained(\n",
    "    model_name, dtype=precision  # gpt2 -> gpt2-small\n",
    ")\n",
    "src_d_model: int = src_model.cfg.d_model\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Make Source Data\n",
    "source_data = PileUncopyrightedDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    context_size=src_model.cfg.n_ctx,\n",
    ")\n",
    "\n",
    "max_items = 1_500_000  # max number of items in store\n",
    "store = TensorActivationStore(max_items, src_d_model, device)\n",
    "expansion_rate = 4  # 4x expansion\n",
    "# Make Autoencoder|\n",
    "in_width = src_model.cfg.d_model\n",
    "n_features = src_model.cfg.d_model * expansion_rate  # 4x expansion\n",
    "src_model_activation_hook_point = \"blocks.10.hook_resid_pre\"  # start with layer 10\n",
    "autoencoder = SparseAutoencoder(in_width, n_features, torch.zeros(in_width))\n",
    "autoencoder.to(device)\n",
    "\n",
    "# hyper parameter\n",
    "max_activations = 60* 1.5 * max_items\n",
    "print(f\"Training on {max_activations / 10**6} million tokens\")\n",
    "\n",
    "sweep_config = SweepParametersRuntime(\n",
    "    lr=1e-3,\n",
    "    batch_size=4096,\n",
    "    l1_coefficient=5e-3,\n",
    ")\n",
    "\n",
    "config = sweep_config.__dict__\n",
    "config = config | {\n",
    "    \"model_name\": model_name,\n",
    "    \"precision\": precision,\n",
    "    \"max_activations\": max_activations,\n",
    "    \"src_model_activation_hook_point\": src_model_activation_hook_point,\n",
    "    \"max_items\": max_items,\n",
    "    \"n_features\": n_features,\n",
    "    \"expansion_factor\": expansion_rate,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autoencoder width is an important hyperparameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjbloom\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path .cache/wandb/wandb/ wasn't writable, using system temp directory.\n",
      "wandb: WARNING Path .cache/wandb/wandb/ wasn't writable, using system temp directory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/wandb/run-20231109_213818-anvteq2m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jbloom/sparse-autoencoder/runs/anvteq2m' target=\"_blank\">celestial-river-48</a></strong> to <a href='https://wandb.ai/jbloom/sparse-autoencoder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jbloom/sparse-autoencoder' target=\"_blank\">https://wandb.ai/jbloom/sparse-autoencoder</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jbloom/sparse-autoencoder/runs/anvteq2m' target=\"_blank\">https://wandb.ai/jbloom/sparse-autoencoder/runs/anvteq2m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07871a5eea4a496b9591d37e343c701f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total activations trained on:   0%|          | 0/135000000.0 [00:00<?, ?it/s, Generate/train iterations=0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd05157f7494edc80420e7a5517d388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7933988a6a456bbeaf7a83cbcfd548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b112ee7266451692a04589fae786f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111fcfbb76274c4e95a80cccf35680fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491924b171874432be9d444a154e518a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf15882c3e94e1cb6ed111cb24107ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6f534b66964fb1ae53d124457b61cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1763688bd5ef40419779d1a461aa4f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f49c8e0802463382c25f075ce10844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43c96bdf7c4443984ef3ab362aeb442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7330aebec6de408faa5c930709647ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe33e4f6c084eea90b453b5de679f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6bae56ec0f42c48e562e53aa43f2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193d111d01574393ac723202aaf1761d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97502c6462e429ab6d87c89497ce727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ddfbd7f8ea446f9bc8a7fd24dbb16d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05eb2e8be9644a8da348d8f4f29e41e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236d82bcd73b4c699729fffe02a95f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016f50f6183b438e92a869f75921a85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4eea7d64354d45a8cc82b6c1b1534f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad014b0bd4dc4d958657b4cf081f7d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b1d1b3592343a49eedc812fe1392b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f731183099fa400faf1e9477d772287f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a44c3f558a642a4a110486242d8370b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701beb6ecdb3495e87d506efc5131f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ecab1a7a8c47569008da5eca802ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4299cd2ebc65499aaf8f21e7d617cc50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a830cff8df7e413a9841fd791541482c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55917103859840aaae3cf1e60cc34d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916b52d043a843b9b2390ce1f08a3376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca5f239ca634c9980d5cc2fab22ea2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bf810507624205afd4c9b376485555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0401c30bd94d4f17a9db6b0caa1b8dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b4a9b8981b457fa6641adb7c6720e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9d386ae88e40de8bac3ddc09f8122b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fe9bb767dc47479c4549bf76786a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaab4094b9ec4b1eaaa20c5ada387b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13ca21ac2f845dc97b01291dd670bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363af09ea8944c5183363f3fdf3b7e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb268be8f384cda9be868bb0c12282e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b186a6e6ffb4364aa7efb9aa499832f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05e2954bf254ed4b136c91554c4dc2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943aaf580d61425b816e5211d178df67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6505c4fd10ce415da791bbaf2d07748a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03bf82fba3b943d6ab7b4a00f0e73f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85f780670954a91abd5d384c3c27579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c390a548ac450dad1dca5cdf389b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7f33e52e7f43188440245f9a4ecd72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6068381d12684912820d2f8826af652a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7f74170d8b437b94184e66221b3f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Autoencoder:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830c2be354ff4e428f299d6a1be550de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate Activations:   0%|          | 0/1490944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ChunkedEncodingError",
     "evalue": "('Connection broken: IncompleteRead(5187998 bytes read, 55002 more expected)', IncompleteRead(5187998 bytes read, 55002 more expected))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/urllib3/response.py:710\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 710\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    713\u001b[0m     \u001b[39m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[1;32m    714\u001b[0m     \u001b[39m# there is yet no clean way to get at it from this context.\u001b[39;00m\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/urllib3/response.py:835\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    826\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menforce_content_length\n\u001b[1;32m    827\u001b[0m             \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength_remaining \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[39m# raised during streaming, so all calls with incorrect\u001b[39;00m\n\u001b[1;32m    834\u001b[0m             \u001b[39m# Content-Length are caught.\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m             \u001b[39mraise\u001b[39;00m IncompleteRead(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp_bytes_read, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength_remaining)\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m data:\n",
      "\u001b[0;31mIncompleteRead\u001b[0m: IncompleteRead(5187998 bytes read, 55002 more expected)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/urllib3/response.py:936\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 936\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[1;32m    938\u001b[0m     \u001b[39mif\u001b[39;00m data:\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/urllib3/response.py:907\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m<\u001b[39m amt \u001b[39mand\u001b[39;00m data:\n\u001b[1;32m    904\u001b[0m     \u001b[39m# TODO make sure to initially read enough data to get past the headers\u001b[39;00m\n\u001b[1;32m    905\u001b[0m     \u001b[39m# For example, the GZ file header takes 10 bytes, we don't want to read\u001b[39;00m\n\u001b[1;32m    906\u001b[0m     \u001b[39m# it one byte at a time\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_read(amt)\n\u001b[1;32m    908\u001b[0m     decoded_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decode(data, decode_content, flush_decoder)\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/urllib3/response.py:813\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    811\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 813\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[1;32m    814\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen\u001b[39m.\u001b[39;49mthrow(typ, value, traceback)\n\u001b[1;32m    154\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/urllib3/response.py:727\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[39mexcept\u001b[39;00m (HTTPException, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    726\u001b[0m     \u001b[39m# This includes IncompleteRead.\u001b[39;00m\n\u001b[0;32m--> 727\u001b[0m     \u001b[39mraise\u001b[39;00m ProtocolError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConnection broken: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m, e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    729\u001b[0m \u001b[39m# If no exception is thrown, we should avoid cleaning up\u001b[39;00m\n\u001b[1;32m    730\u001b[0m \u001b[39m# unnecessarily.\u001b[39;00m\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection broken: IncompleteRead(5187998 bytes read, 55002 more expected)', IncompleteRead(5187998 bytes read, 55002 more expected))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mChunkedEncodingError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/root/sparse_autoencoder/dev/gpt2_small_sae_training.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/sparse_autoencoder/dev/gpt2_small_sae_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m wandb\u001b[39m.\u001b[39minit(project\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse-autoencoder\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mdir\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.cache/wandb\u001b[39m\u001b[39m\"\u001b[39m, config\u001b[39m=\u001b[39mconfig)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/sparse_autoencoder/dev/gpt2_small_sae_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m pipeline(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/sparse_autoencoder/dev/gpt2_small_sae_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     src_model\u001b[39m=\u001b[39;49msrc_model,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/sparse_autoencoder/dev/gpt2_small_sae_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     src_model_activation_hook_point\u001b[39m=\u001b[39;49msrc_model_activation_hook_point,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/sparse_autoencoder/dev/gpt2_small_sae_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     src_model_activation_layer\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,  \u001b[39m# why do we need to specify this as well?\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/sparse_autoencoder/dev/gpt2_small_sae_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     source_dataset\u001b[39m=\u001b[39;49msource_data,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/sparse_autoencoder/dev/gpt2_small_sae_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     activation_store\u001b[39m=\u001b[39;49mstore,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/sparse_autoencoder/dev/gpt2_small_sae_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     num_activations_before_training\u001b[39m=\u001b[39;49mmax_items,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/sparse_autoencoder/dev/gpt2_small_sae_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     sweep_parameters\u001b[39m=\u001b[39;49msweep_config,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/sparse_autoencoder/dev/gpt2_small_sae_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     log_artifacts\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/sparse_autoencoder/dev/gpt2_small_sae_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     autoencoder\u001b[39m=\u001b[39;49mautoencoder,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/sparse_autoencoder/dev/gpt2_small_sae_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/sparse_autoencoder/dev/gpt2_small_sae_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     max_activations\u001b[39m=\u001b[39;49mmax_activations,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/sparse_autoencoder/dev/gpt2_small_sae_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22566173744149227d/root/sparse_autoencoder/dev/gpt2_small_sae_training.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m wandb\u001b[39m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/sparse_autoencoder/sparse_autoencoder/train/pipeline.py:126\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(src_model, src_model_activation_hook_point, src_model_activation_layer, source_dataset, activation_store, num_activations_before_training, autoencoder, source_dataset_batch_size, sweep_parameters, log_artifacts, device, max_activations)\u001b[0m\n\u001b[1;32m    123\u001b[0m activation_store\u001b[39m.\u001b[39mempty()  \u001b[39m# In case it was filled by a different run\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39m# Add activations to the store\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m generate_activations(\n\u001b[1;32m    127\u001b[0m     src_model,\n\u001b[1;32m    128\u001b[0m     src_model_activation_layer,\n\u001b[1;32m    129\u001b[0m     src_model_activation_hook_point,\n\u001b[1;32m    130\u001b[0m     activation_store,\n\u001b[1;32m    131\u001b[0m     source_data_iterator,\n\u001b[1;32m    132\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    133\u001b[0m     context_size\u001b[39m=\u001b[39;49msource_dataset\u001b[39m.\u001b[39;49mcontext_size,\n\u001b[1;32m    134\u001b[0m     num_items\u001b[39m=\u001b[39;49mnum_activations_before_training,\n\u001b[1;32m    135\u001b[0m     batch_size\u001b[39m=\u001b[39;49msource_dataset_batch_size,\n\u001b[1;32m    136\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(activation_store) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    138\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/sparse_autoencoder/sparse_autoencoder/train/generate_activations.py:80\u001b[0m, in \u001b[0;36mgenerate_activations\u001b[0;34m(model, layer, cache_name, store, source_data, context_size, batch_size, num_items, device)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m# Loop through the dataloader until the store reaches the desired size\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad(), tqdm(\n\u001b[1;32m     74\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGenerate Activations\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     75\u001b[0m     total\u001b[39m=\u001b[39mtotal \u001b[39m-\u001b[39m total \u001b[39m%\u001b[39m activations_per_batch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m     dynamic_ncols\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     79\u001b[0m ) \u001b[39mas\u001b[39;00m progress_bar:\n\u001b[0;32m---> 80\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m source_data:\n\u001b[1;32m     81\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(store) \u001b[39m+\u001b[39m activations_per_batch \u001b[39m>\u001b[39m total:\n\u001b[1;32m     82\u001b[0m             \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/sparse_autoencoder/sparse_autoencoder/train/pipeline.py:55\u001b[0m, in \u001b[0;36mstateful_dataloader_iterable\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstateful_dataloader_iterable\u001b[39m(\n\u001b[1;32m     22\u001b[0m     dataloader: DataLoader[TorchTokenizedPrompts]\n\u001b[1;32m     23\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterable[TorchTokenizedPrompts]:\n\u001b[1;32m     24\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create a stateful dataloader iterable.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[39m    Create an iterable that maintains it's position in the dataloader between loops.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m        Stateful iterable over the data in the dataloader.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     \u001b[39myield from\u001b[39;00m dataloader\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:32\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m possibly_batched_index:\n\u001b[1;32m     31\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m         data\u001b[39m.\u001b[39mappend(\u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_iter))\n\u001b[1;32m     33\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mended \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/datasets/iterable_dataset.py:1379\u001b[0m, in \u001b[0;36mIterableDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m         \u001b[39myield\u001b[39;00m formatter\u001b[39m.\u001b[39mformat_row(pa_table)\n\u001b[1;32m   1377\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m-> 1379\u001b[0m \u001b[39mfor\u001b[39;00m key, example \u001b[39min\u001b[39;00m ex_iterable:\n\u001b[1;32m   1380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures:\n\u001b[1;32m   1381\u001b[0m         \u001b[39m# `IterableDataset` automatically fills missing columns with None.\u001b[39;00m\n\u001b[1;32m   1382\u001b[0m         \u001b[39m# This is done with `_apply_feature_types_on_example`.\u001b[39;00m\n\u001b[1;32m   1383\u001b[0m         example \u001b[39m=\u001b[39m _apply_feature_types_on_example(\n\u001b[1;32m   1384\u001b[0m             example, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, token_per_repo_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_token_per_repo_id\n\u001b[1;32m   1385\u001b[0m         )\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/datasets/iterable_dataset.py:982\u001b[0m, in \u001b[0;36mBufferShuffledExamplesIterable.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[39m# this is the shuffle buffer that we keep in memory\u001b[39;00m\n\u001b[1;32m    981\u001b[0m mem_buffer \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 982\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mex_iterable:\n\u001b[1;32m    983\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mem_buffer) \u001b[39m==\u001b[39m buffer_size:  \u001b[39m# if the buffer is full, pick and example from it\u001b[39;00m\n\u001b[1;32m    984\u001b[0m         i \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(indices_iterator)\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/datasets/iterable_dataset.py:678\u001b[0m, in \u001b[0;36mMappedExamplesIterable.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[39myield from\u001b[39;00m ArrowExamplesIterable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_arrow, {})\n\u001b[1;32m    677\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 678\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter()\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/datasets/iterable_dataset.py:700\u001b[0m, in \u001b[0;36mMappedExamplesIterable._iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39mfor\u001b[39;00m key, example \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m    694\u001b[0m     \u001b[39m# If `batched`, first build the batch, if `batch_size` is None or <=0, then the batch is the whole dataset\u001b[39;00m\n\u001b[1;32m    695\u001b[0m     iterator_batch \u001b[39m=\u001b[39m (\n\u001b[1;32m    696\u001b[0m         iterator\n\u001b[1;32m    697\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    698\u001b[0m         \u001b[39melse\u001b[39;00m islice(iterator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m    699\u001b[0m     )\n\u001b[0;32m--> 700\u001b[0m     key_examples_list \u001b[39m=\u001b[39m [(key, example)] \u001b[39m+\u001b[39m [(key, example) \u001b[39mfor\u001b[39;00m key, example \u001b[39min\u001b[39;00m iterator_batch]\n\u001b[1;32m    701\u001b[0m     keys, examples \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mkey_examples_list)\n\u001b[1;32m    702\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop_last_batch\n\u001b[1;32m    704\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    705\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    706\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(examples) \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\n\u001b[1;32m    707\u001b[0m     ):  \u001b[39m# ignore last batch\u001b[39;00m\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/datasets/iterable_dataset.py:700\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39mfor\u001b[39;00m key, example \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m    694\u001b[0m     \u001b[39m# If `batched`, first build the batch, if `batch_size` is None or <=0, then the batch is the whole dataset\u001b[39;00m\n\u001b[1;32m    695\u001b[0m     iterator_batch \u001b[39m=\u001b[39m (\n\u001b[1;32m    696\u001b[0m         iterator\n\u001b[1;32m    697\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    698\u001b[0m         \u001b[39melse\u001b[39;00m islice(iterator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m    699\u001b[0m     )\n\u001b[0;32m--> 700\u001b[0m     key_examples_list \u001b[39m=\u001b[39m [(key, example)] \u001b[39m+\u001b[39m [(key, example) \u001b[39mfor\u001b[39;00m key, example \u001b[39min\u001b[39;00m iterator_batch]\n\u001b[1;32m    701\u001b[0m     keys, examples \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mkey_examples_list)\n\u001b[1;32m    702\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop_last_batch\n\u001b[1;32m    704\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    705\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    706\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(examples) \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\n\u001b[1;32m    707\u001b[0m     ):  \u001b[39m# ignore last batch\u001b[39;00m\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/datasets/iterable_dataset.py:320\u001b[0m, in \u001b[0;36mShuffledDataSourcesArrowExamplesIterable.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m kwargs_with_shuffled_shards \u001b[39m=\u001b[39m _shuffle_gen_kwargs(rng, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[1;32m    319\u001b[0m formatter \u001b[39m=\u001b[39m PythonFormatter()\n\u001b[0;32m--> 320\u001b[0m \u001b[39mfor\u001b[39;00m key, pa_table \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_tables_fn(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs_with_shuffled_shards):\n\u001b[1;32m    321\u001b[0m     \u001b[39mfor\u001b[39;00m pa_subtable \u001b[39min\u001b[39;00m pa_table\u001b[39m.\u001b[39mto_reader(max_chunksize\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mARROW_READER_BATCH_SIZE_IN_DATASET_ITER):\n\u001b[1;32m    322\u001b[0m         formatted_batch \u001b[39m=\u001b[39m formatter\u001b[39m.\u001b[39mformat_batch(pa_subtable)\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/datasets/packaged_modules/json/json.py:107\u001b[0m, in \u001b[0;36mJson._generate_tables\u001b[0;34m(self, files)\u001b[0m\n\u001b[1;32m    103\u001b[0m encoding_errors \u001b[39m=\u001b[39m (\n\u001b[1;32m    104\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mencoding_errors \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mencoding_errors \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m )\n\u001b[1;32m    106\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     batch \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49mread(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mchunksize)\n\u001b[1;32m    108\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m batch:\n\u001b[1;32m    109\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/datasets/download/streaming_download_manager.py:333\u001b[0m, in \u001b[0;36m_add_retries_to_file_obj_read_method.<locals>.read_with_retries\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[39mfor\u001b[39;00m retry \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, max_retries \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    332\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 333\u001b[0m         out \u001b[39m=\u001b[39m read(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    334\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     \u001b[39mexcept\u001b[39;00m (ClientError, \u001b[39mTimeoutError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/fsspec/spec.py:1856\u001b[0m, in \u001b[0;36mAbstractBufferedFile.read\u001b[0;34m(self, length)\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[39mif\u001b[39;00m length \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1854\u001b[0m     \u001b[39m# don't even bother calling fetch\u001b[39;00m\n\u001b[1;32m   1855\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1856\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache\u001b[39m.\u001b[39;49m_fetch(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc \u001b[39m+\u001b[39;49m length)\n\u001b[1;32m   1857\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(out)\n\u001b[1;32m   1858\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/fsspec/caching.py:189\u001b[0m, in \u001b[0;36mReadAheadCache._fetch\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m    187\u001b[0m     part \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m end \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize, end \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocksize)\n\u001b[0;32m--> 189\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetcher(start, end)  \u001b[39m# new block replaces old\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart \u001b[39m=\u001b[39m start\n\u001b[1;32m    191\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache)\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/huggingface_hub/hf_file_system.py:444\u001b[0m, in \u001b[0;36mHfFileSystemFile._fetch_range\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m    433\u001b[0m headers \u001b[39m=\u001b[39m {\n\u001b[1;32m    434\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrange\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbytes=\u001b[39m\u001b[39m{\u001b[39;00mstart\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mend\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    435\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs\u001b[39m.\u001b[39m_api\u001b[39m.\u001b[39m_build_hf_headers(),\n\u001b[1;32m    436\u001b[0m }\n\u001b[1;32m    437\u001b[0m url \u001b[39m=\u001b[39m hf_hub_url(\n\u001b[1;32m    438\u001b[0m     repo_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolved_path\u001b[39m.\u001b[39mrepo_id,\n\u001b[1;32m    439\u001b[0m     revision\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolved_path\u001b[39m.\u001b[39mrevision,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    442\u001b[0m     endpoint\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs\u001b[39m.\u001b[39mendpoint,\n\u001b[1;32m    443\u001b[0m )\n\u001b[0;32m--> 444\u001b[0m r \u001b[39m=\u001b[39m http_backoff(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m    445\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m    446\u001b[0m \u001b[39mreturn\u001b[39;00m r\u001b[39m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:267\u001b[0m, in \u001b[0;36mhttp_backoff\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mseek(io_obj_initial_pos)\n\u001b[1;32m    266\u001b[0m \u001b[39m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m response \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    268\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m retry_on_status_codes:\n\u001b[1;32m    269\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/requests/sessions.py:725\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[39mif\u001b[39;00m allow_redirects:\n\u001b[1;32m    723\u001b[0m     \u001b[39m# Redirect resolving generator.\u001b[39;00m\n\u001b[1;32m    724\u001b[0m     gen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolve_redirects(r, request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 725\u001b[0m     history \u001b[39m=\u001b[39m [resp \u001b[39mfor\u001b[39;00m resp \u001b[39min\u001b[39;00m gen]\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    727\u001b[0m     history \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/requests/sessions.py:725\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[39mif\u001b[39;00m allow_redirects:\n\u001b[1;32m    723\u001b[0m     \u001b[39m# Redirect resolving generator.\u001b[39;00m\n\u001b[1;32m    724\u001b[0m     gen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolve_redirects(r, request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 725\u001b[0m     history \u001b[39m=\u001b[39m [resp \u001b[39mfor\u001b[39;00m resp \u001b[39min\u001b[39;00m gen]\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    727\u001b[0m     history \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/requests/sessions.py:266\u001b[0m, in \u001b[0;36mSessionRedirectMixin.resolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[39myield\u001b[39;00m req\n\u001b[1;32m    264\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 266\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\n\u001b[1;32m    267\u001b[0m         req,\n\u001b[1;32m    268\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    269\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    270\u001b[0m         verify\u001b[39m=\u001b[39;49mverify,\n\u001b[1;32m    271\u001b[0m         cert\u001b[39m=\u001b[39;49mcert,\n\u001b[1;32m    272\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    273\u001b[0m         allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    274\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49madapter_kwargs,\n\u001b[1;32m    275\u001b[0m     )\n\u001b[1;32m    277\u001b[0m     extract_cookies_to_jar(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcookies, prepared_request, resp\u001b[39m.\u001b[39mraw)\n\u001b[1;32m    279\u001b[0m     \u001b[39m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/requests/sessions.py:747\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[0;32m--> 747\u001b[0m     r\u001b[39m.\u001b[39;49mcontent\n\u001b[1;32m    749\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter_content(CONTENT_CHUNK_SIZE)) \u001b[39mor\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content_consumed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[39m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[39m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m~/sparse_autoencoder/.venv/lib/python3.10/site-packages/requests/models.py:818\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 818\u001b[0m     \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n\u001b[1;32m    819\u001b[0m \u001b[39mexcept\u001b[39;00m DecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    820\u001b[0m     \u001b[39mraise\u001b[39;00m ContentDecodingError(e)\n",
      "\u001b[0;31mChunkedEncodingError\u001b[0m: ('Connection broken: IncompleteRead(5187998 bytes read, 55002 more expected)', IncompleteRead(5187998 bytes read, 55002 more expected))"
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"sparse-autoencoder\", dir=\".cache/wandb\", config=config)\n",
    "\n",
    "pipeline(\n",
    "    src_model=src_model,\n",
    "    src_model_activation_hook_point=src_model_activation_hook_point,\n",
    "    src_model_activation_layer=10,  # why do we need to specify this as well?\n",
    "    source_dataset=source_data,\n",
    "    activation_store=store,\n",
    "    num_activations_before_training=max_items,\n",
    "    sweep_parameters=sweep_config,\n",
    "    log_artifacts=True,\n",
    "    autoencoder=autoencoder,\n",
    "    device=device,\n",
    "    max_activations=max_activations,\n",
    ")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
